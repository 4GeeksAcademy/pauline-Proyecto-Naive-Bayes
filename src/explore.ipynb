{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Explore here"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 95,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Your code here\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn.feature_extraction.text import CountVectorizer\n",
                "from sklearn.naive_bayes import MultinomialNB,GaussianNB,BernoulliNB\n",
                "from sklearn.metrics import classification_report\n",
                "from sklearn.model_selection import GridSearchCV\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 96,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>review</th>\n",
                            "      <th>polarity</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>0</th>\n",
                            "      <td>privacy at least put some option appear offli...</td>\n",
                            "      <td>0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1</th>\n",
                            "      <td>messenger issues ever since the last update, ...</td>\n",
                            "      <td>0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>2</th>\n",
                            "      <td>profile any time my wife or anybody has more ...</td>\n",
                            "      <td>0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>3</th>\n",
                            "      <td>the new features suck for those of us who don...</td>\n",
                            "      <td>0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>4</th>\n",
                            "      <td>forced reload on uploading pic on replying co...</td>\n",
                            "      <td>0</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "                                              review  polarity\n",
                            "0   privacy at least put some option appear offli...         0\n",
                            "1   messenger issues ever since the last update, ...         0\n",
                            "2   profile any time my wife or anybody has more ...         0\n",
                            "3   the new features suck for those of us who don...         0\n",
                            "4   forced reload on uploading pic on replying co...         0"
                        ]
                    },
                    "execution_count": 96,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "df = pd.read_csv('/workspaces/pauline-Proyecto-Naive-Bayes/data/raw/playstore_reviews.csv')\n",
                "#Como dicho en las instrucciones, eliminamos package_name, ya que de eso no depende la clasificación de la reseña\n",
                "df.drop(['package_name'], axis=1, inplace=True)\n",
                "df.head()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 97,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "(891, 2)\n",
                        "<class 'pandas.core.frame.DataFrame'>\n",
                        "RangeIndex: 891 entries, 0 to 890\n",
                        "Data columns (total 2 columns):\n",
                        " #   Column    Non-Null Count  Dtype \n",
                        "---  ------    --------------  ----- \n",
                        " 0   review    891 non-null    object\n",
                        " 1   polarity  891 non-null    int64 \n",
                        "dtypes: int64(1), object(1)\n",
                        "memory usage: 14.0+ KB\n",
                        "None\n"
                    ]
                },
                {
                    "data": {
                        "text/plain": [
                            "0"
                        ]
                    },
                    "execution_count": 97,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "#Quiero saber cuantas filas hay :\n",
                "print(df.shape)\n",
                "#Tipo de data y check si hay nulos/faltantes\n",
                "print(df.info())\n",
                "# Revisamos que no haya fila duplicada:\n",
                "sum(df.duplicated())"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 98,
            "metadata": {},
            "outputs": [],
            "source": [
                "#Eliminar espacios y convertir a minúsculas el texto: \n",
                "df[\"review\"] = df[\"review\"].str.strip().str.lower()\n",
                "\n",
                "#Y dividimos los datos en conjuntos de entrenamiento y testeo\n",
                "X = df['review']\n",
                "y = df[['polarity']]\n",
                "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 99,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "331    just did the latest update on viber and yet ag...\n",
                            "733    keeps crashing it only works well in extreme d...\n",
                            "382    the fail boat has arrived the 6.0 version is t...\n",
                            "704    superfast, just as i remember it ! opera mini ...\n",
                            "813    installed and immediately deleted this crap i ...\n",
                            "Name: review, dtype: object"
                        ]
                    },
                    "execution_count": 99,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "X_train.head()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 100,
            "metadata": {},
            "outputs": [],
            "source": [
                "vectorizer = CountVectorizer(stop_words = \"english\") #ese de stop_word se usa para eliminar las palabras más comunes y sin valor informativo\n",
                "X_train_vec = vectorizer.fit_transform(X_train)\n",
                "X_test_vec = vectorizer.transform(X_test)\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 101,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "array(['000', '04', '0x', ..., 'žŕ', 'žŕľ', 'ˇŕ'],\n",
                            "      shape=(3310,), dtype=object)"
                        ]
                    },
                    "execution_count": 101,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "#Chequeamos con algunas palabras o características que han sido quitadas:\n",
                "vectorizer.get_feature_names_out()\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 102,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "array([0, 0, 0, ..., 0, 0, 0], shape=(3310,))"
                        ]
                    },
                    "execution_count": 102,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "X_test_vec.toarray()[1]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 103,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Review de prueba: whatsapp i use this app now that blackberry messenger has basically gone away. my friends & family live all over the world. this really helps keep us in touch!\n",
                        "\n",
                        "Palabras del conjunto de entrenamiento que también aparecen en la review de test junto con su aparición:\n",
                        "\n",
                        "Palabra: \"app\"\n",
                        "--> Aparece 1 veces en la review.\n",
                        "Palabra: \"away\"\n",
                        "--> Aparece 1 veces en la review.\n",
                        "Palabra: \"basically\"\n",
                        "--> Aparece 1 veces en la review.\n",
                        "Palabra: \"family\"\n",
                        "--> Aparece 1 veces en la review.\n",
                        "Palabra: \"friends\"\n",
                        "--> Aparece 1 veces en la review.\n",
                        "Palabra: \"gone\"\n",
                        "--> Aparece 1 veces en la review.\n",
                        "Palabra: \"helps\"\n",
                        "--> Aparece 1 veces en la review.\n",
                        "Palabra: \"live\"\n",
                        "--> Aparece 1 veces en la review.\n",
                        "Palabra: \"messenger\"\n",
                        "--> Aparece 1 veces en la review.\n",
                        "Palabra: \"really\"\n",
                        "--> Aparece 1 veces en la review.\n",
                        "Palabra: \"touch\"\n",
                        "--> Aparece 1 veces en la review.\n",
                        "Palabra: \"use\"\n",
                        "--> Aparece 1 veces en la review.\n",
                        "Palabra: \"whatsapp\"\n",
                        "--> Aparece 1 veces en la review.\n",
                        "Palabra: \"world\"\n",
                        "--> Aparece 1 veces en la review.\n"
                    ]
                }
            ],
            "source": [
                "#Mostrar una review de prueba (texto)\n",
                "print(f'Review de prueba: {X_test.iloc[1]}')\n",
                "\n",
                "\n",
                "print('\\nPalabras del conjunto de entrenamiento que también aparecen en la review de test junto con su aparición:\\n')\n",
                "for i, cont in enumerate(X_test_vec.toarray()[1]):\n",
                "  if cont!=0:\n",
                "    print(f'Palabra: \"{vectorizer.get_feature_names_out()[i]}\"')\n",
                "    print(f'--> Aparece {cont} veces en la review.')\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Paso 3: Construye un naive bayes.** Elegimos **Multinomial** porque variable predictora es categorica, con varias posibilidades.   (Gauss es para regresion y Bernoulli cuando las variables son binarias)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 104,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Evaluación del modelo:               precision    recall  f1-score   support\n",
                        "\n",
                        "           0       0.84      0.90      0.87       126\n",
                        "           1       0.73      0.60      0.66        53\n",
                        "\n",
                        "    accuracy                           0.82       179\n",
                        "   macro avg       0.79      0.75      0.77       179\n",
                        "weighted avg       0.81      0.82      0.81       179\n",
                        "\n",
                        "\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/home/vscode/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:1408: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
                        "  y = column_or_1d(y, warn=True)\n"
                    ]
                }
            ],
            "source": [
                "#Inicializar y entrenar el clasificador Naive Bayes Multinomial\n",
                "clf_multi = MultinomialNB().fit(X_train_vec, y_train)\n",
                "\n",
                "# Realizar predicciones en el conjunto de prueba\n",
                "y_pred = clf_multi.predict(X_test_vec)\n",
                "\n",
                "\n",
                "\n",
                "\n",
                "# Evaluar el rendimiento del modelo\n",
                "print(f'Evaluación del modelo: {classification_report(y_test, y_pred)}\\n')\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "- **Accuracy** (=exactitud) --> alta con 82%\n",
                "\n",
                "**Precision** :\n",
                "- Clase 0 (negativa): 0.84 --> de todas las veces que el modelo predijo que una muestra pertenecía a la clase 0, un 84% de esas veces realmente era 0.\n",
                "- Clase 1 (positiva): 0.73 --> de todas las veces que el modelo predijo que una muestra pertenecía a la clase 1, un 73% de esas veces realmente era 1.\n",
                "\n",
                "**Recall** : sensibilidad\n",
                "- Clase 0 (negativa): 0.90. El modelo identificó correctamente el 90% de todas las instancias que realmente pertenecen a la clase 0.\n",
                "- Clase 1 (positiva): 0.60. Solo el 60% de las instancias que realmente pertenecen a la clase 1 fueron correctamente identificadas por el modelo.\n",
                "\n",
                "**F1** = Recall vs precion :\n",
                "\n",
                "- Clase 0 (negativa): 0.87. Esta es una puntuación bastante buena, lo que indica que la precisión y el recall de la clase 0 están equilibrados y son bastante altos.\n",
                "- Clase 1 (positiva): 0.66. Más de 20 puntos más bajo, el modelo tiene más dificultades con la clase de comentarios positivos.\n",
                "\n",
                "\n",
                "El modelo tiene un buen rendimiento para comentarios negativos (alta precisión y recall), pero más dificultades a predecir comentarios positivos (baja recall y precisión comparado con 0).\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Testeamos los 2 otros\n",
                "- **GAUSS**:\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 105,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Evaluación del modelo:               precision    recall  f1-score   support\n",
                        "\n",
                        "           0       0.85      0.88      0.86       126\n",
                        "           1       0.69      0.62      0.65        53\n",
                        "\n",
                        "    accuracy                           0.80       179\n",
                        "   macro avg       0.77      0.75      0.76       179\n",
                        "weighted avg       0.80      0.80      0.80       179\n",
                        "\n",
                        "\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/home/vscode/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:1408: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
                        "  y = column_or_1d(y, warn=True)\n"
                    ]
                }
            ],
            "source": [
                "#probamos con los 2 otros : \n",
                "\n",
                "#Inicializar y entrenar el clasificador Naive GaussianNB\n",
                "clf_gauss = GaussianNB().fit(X_train_vec.toarray(), y_train)\n",
                "\n",
                "#Realizar predicciones en el conjunto de prueba\n",
                "y_pred_gauss = clf_gauss.predict(X_test_vec.toarray())\n",
                "\n",
                "\n",
                "#Evaluar el rendimiento del modelo\n",
                "print(f'Evaluación del modelo: {classification_report(y_test, y_pred_gauss)}\\n')\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "\n",
                "Resultados bastante similares que con m ultinomial\n",
                "\n",
                " **Accuracy** (=exactitud) --> alta con 80%\n",
                "\n",
                "**Precision**:\n",
                "- Clase 0 (negativa): 0.85 --> de todas las veces que el modelo predijo que una muestra pertenecía a la clase 0, un 85% de esas veces realmente era 0.\n",
                "- Clase 1 (positiva): 0.69 --> de todas las veces que el modelo predijo que una muestra pertenecía a la clase 1, un 69% de esas veces realmente era 1.\n",
                "\n",
                "**Recall**: sensibilidad\n",
                "- Clase 0 (negativa): 0.88. El modelo identificó correctamente el 88% de todas las instancias que realmente pertenecen a la clase 0.\n",
                "- Clase 1 (positiva): 0.62. Solo el 62% de las instancias que realmente pertenecen a la clase 1 fueron correctamente identificadas por el modelo.\n",
                "\n",
                "**F1** = Recall vs precisión :\n",
                "\n",
                "- Clase 0 (negativa): 0.86. precisión y el recall de la clase 0 están equilibrados y son bastante altos.\n",
                "- Clase 1 (positiva): 0.65. Igual, más de 20 puntos más bajo, el modelo tiene más dificultades con la clase de comentarios positivos.\n",
                "\n",
                "El modelo tiene un buen rendimiento para comentarios negativos (alta precisión y recall), pero más dificultades a predecir comentarios positivos (baja recall y precisión comparado con 0)."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "- BERNOUILLI"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 106,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Evaluación del modelo:               precision    recall  f1-score   support\n",
                        "\n",
                        "           0       0.79      0.93      0.85       126\n",
                        "           1       0.70      0.40      0.51        53\n",
                        "\n",
                        "    accuracy                           0.77       179\n",
                        "   macro avg       0.74      0.66      0.68       179\n",
                        "weighted avg       0.76      0.77      0.75       179\n",
                        "\n",
                        "\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/home/vscode/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:1408: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
                        "  y = column_or_1d(y, warn=True)\n"
                    ]
                }
            ],
            "source": [
                "#Inicializar y entrenar el clasificador Naive BernoulliNB\n",
                "clf_ber = BernoulliNB()\n",
                "clf_ber.fit(X_train_vec.toarray(), y_train)\n",
                "\n",
                "#Realizar predicciones en el conjunto de prueba\n",
                "y_pred_ber = clf_ber.predict(X_test_vec.toarray())\n",
                "\n",
                "#Evaluar el rendimiento del modelo\n",
                "print(f'Evaluación del modelo: {classification_report(y_test, y_pred_ber)}\\n')\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "\n",
                "**Accuracy** (=exactitud) --> 77%, lo que es más bajo que el modelo Gaussiano y también inferior al modelo base.\n",
                "\n",
                "**Precision:**\n",
                "- Clase 0 (negativa): 0.79 --> De todas las veces que el modelo predijo que una muestra pertenecía a la clase 0, un 79% de esas veces realmente era 0.\n",
                "- Clase 1 (positiva): 0.70 --> De todas las veces que el modelo predijo que una muestra pertenecía a la clase 1, un 70% de esas veces realmente era 1.\n",
                "\n",
                "**Recall**: sensibilidad\n",
                "\n",
                "- Clase 0 (negativa): 0.93. El modelo identificó correctamente el 93% de todas las instancias que realmente pertenecen a la clase 0.\n",
                "- Clase 1 (positiva): 0.40. Solo el 40% de las instancias que realmente pertenecen a la clase 1 fueron correctamente identificadas por el modelo.\n",
                "\n",
                "**F1** = Recall vs precisión:\n",
                "- Clase 0 (negativa): 0.85. Al igual que el modelo Gaussiano, el modelo Bernoulli tiene un buen equilibrio entre precisión y recall para la clase 0.\n",
                "- Clase 1 (positiva): 0.51. Mucho más baja =  dificultades del modelo para clasificar correctamente los comentarios positivos.\n",
                "\n",
                "Todos los indicatores son más bajos que los modelos anteriores, sobre todo por los comentarios negativos, solo 40% de sensibilidad u 0,51 F1. indica que no es muy fiable,\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Conclusion sobre comparación de los 3 modelos**:\n",
                "\n",
                "El *mejor modelo es el multinonmial*, que hemos hecho primer : \n",
                "- mejor accuracy\n",
                "- % más alto para precision, recall y F1\n",
                "- promedio ponderado (miramos mejor eso porque el conjunto esta bastante desbalanceado) también mejor más altos en todos los casos, que con Gauss o Bernoulli."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Paso 4: Optimización del modelo multinomial :"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 110,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
                        "La mejor valor para alpha es: {'alpha': 0.5}\n"
                    ]
                }
            ],
            "source": [
                "#Alpha = suavización = principal hiperparametro de Bayes Multinomial, vamos probar con varias valores y usando GridSearchCV:\n",
                "\n",
                "param_grid = {'alpha': [0.1, 0.5, 1, 2, 5, 10],  #Valores comunes para alpha\n",
                "              } \n",
                "\n",
                "#Clasificador:\n",
                "nb = MultinomialNB()\n",
                "\n",
                "#GridSearchCV para buscar el mejor valor de alpha y fit_prior\n",
                "grid_search = GridSearchCV(estimator=nb, param_grid=param_grid, cv=5, n_jobs=-1, verbose=1)\n",
                "\n",
                "\n",
                "#Ajustar el modelo con los datos de entrenamiento\n",
                "grid_search.fit(X_train_vec, y_train)\n",
                "\n",
                "print(f'La mejor valor para alpha es: {grid_search.best_params_}')\n",
                "\n",
                "\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 111,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Evaluación del modelo con GridSearchCV y optimización de hiperparámetros:\n",
                        "              precision    recall  f1-score   support\n",
                        "\n",
                        "           0       0.86      0.90      0.88       126\n",
                        "           1       0.73      0.66      0.69        53\n",
                        "\n",
                        "    accuracy                           0.83       179\n",
                        "   macro avg       0.80      0.78      0.79       179\n",
                        "weighted avg       0.82      0.83      0.82       179\n",
                        "\n"
                    ]
                }
            ],
            "source": [
                "#Evaluar el modelo con el mejor alpha encontrado\n",
                "y_pred_optimized = grid_search.best_estimator_.predict(X_test_vec)\n",
                "print(f'Evaluación del modelo con GridSearchCV y optimización de hiperparámetros:')\n",
                "print(classification_report(y_test, y_pred_optimized))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "#VS volvemos a poner evaluación del modelo antes de optimisación :               \n",
                "#                precision    recall  f1-score   support\n",
                "\n",
                "#           0       0.84      0.90      0.87       126\n",
                "#           1       0.73      0.60      0.66        53\n",
                "\n",
                "#    accuracy                           0.82       179\n",
                "#   macro avg       0.79      0.75      0.77       179\n",
                "#weighted avg       0.81      0.82      0.81       179\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**El model mejoró** : \n",
                "Accuracy subó a 83 % (+ 1 punto) y todos los resultados son = o mejores que antes de la optimización"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 119,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "['/workspaces/pauline-Proyecto-Naive-Bayes/models/modelo_multinomial.pkl']"
                        ]
                    },
                    "execution_count": 119,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "\n",
                "\n",
                "#Guardar el modelo en un archivo\n",
                "import joblib\n",
                "joblib.dump(grid_search.best_estimator_, '/workspaces/pauline-Proyecto-Naive-Bayes/models/modelo_multinomial.pkl')\n"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.12"
        },
        "orig_nbformat": 4
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
